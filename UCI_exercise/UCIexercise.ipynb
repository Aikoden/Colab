{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyT89JQAXQpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2efca7e4-3452-4af1-fb64-60169526083e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "列名:\n",
            "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
            "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
            "       'previous', 'poutcome', 'y'],\n",
            "      dtype='object')\n",
            "\n",
            "各列のデータ型:\n",
            "age           int64\n",
            "job          object\n",
            "marital      object\n",
            "education    object\n",
            "default      object\n",
            "balance       int64\n",
            "housing      object\n",
            "loan         object\n",
            "contact      object\n",
            "day           int64\n",
            "month        object\n",
            "duration      int64\n",
            "campaign      int64\n",
            "pdays         int64\n",
            "previous      int64\n",
            "poutcome     object\n",
            "y            object\n",
            "dtype: object\n",
            "\n",
            "「job」列のユニークな値:\n",
            "['unemployed' 'services' 'management' 'blue-collar' 'self-employed'\n",
            " 'technician' 'entrepreneur' 'admin.' 'student' 'housemaid' 'retired'\n",
            " 'unknown']\n",
            "\n",
            "データセットの基本情報:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4521 entries, 0 to 4520\n",
            "Data columns (total 17 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   age        4521 non-null   int64 \n",
            " 1   job        4521 non-null   object\n",
            " 2   marital    4521 non-null   object\n",
            " 3   education  4521 non-null   object\n",
            " 4   default    4521 non-null   object\n",
            " 5   balance    4521 non-null   int64 \n",
            " 6   housing    4521 non-null   object\n",
            " 7   loan       4521 non-null   object\n",
            " 8   contact    4521 non-null   object\n",
            " 9   day        4521 non-null   int64 \n",
            " 10  month      4521 non-null   object\n",
            " 11  duration   4521 non-null   int64 \n",
            " 12  campaign   4521 non-null   int64 \n",
            " 13  pdays      4521 non-null   int64 \n",
            " 14  previous   4521 non-null   int64 \n",
            " 15  poutcome   4521 non-null   object\n",
            " 16  y          4521 non-null   object\n",
            "dtypes: int64(7), object(10)\n",
            "memory usage: 600.6+ KB\n",
            "None\n",
            "\n",
            "最初の5行のデータ:\n",
            "   age          job  marital  education default  balance housing loan  \\\n",
            "0   30   unemployed  married    primary      no     1787      no   no   \n",
            "1   33     services  married  secondary      no     4789     yes  yes   \n",
            "2   35   management   single   tertiary      no     1350     yes   no   \n",
            "3   30   management  married   tertiary      no     1476     yes  yes   \n",
            "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
            "\n",
            "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
            "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
            "1  cellular   11   may       220         1    339         4  failure  no  \n",
            "2  cellular   16   apr       185         1    330         1  failure  no  \n",
            "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
            "4   unknown    5   may       226         1     -1         0  unknown  no  \n",
            "\n",
            "数値列の記述統計情報:\n",
            "               age       balance          day     duration     campaign  \\\n",
            "count  4521.000000   4521.000000  4521.000000  4521.000000  4521.000000   \n",
            "mean     41.170095   1422.657819    15.915284   263.961292     2.793630   \n",
            "std      10.576211   3009.638142     8.247667   259.856633     3.109807   \n",
            "min      19.000000  -3313.000000     1.000000     4.000000     1.000000   \n",
            "25%      33.000000     69.000000     9.000000   104.000000     1.000000   \n",
            "50%      39.000000    444.000000    16.000000   185.000000     2.000000   \n",
            "75%      49.000000   1480.000000    21.000000   329.000000     3.000000   \n",
            "max      87.000000  71188.000000    31.000000  3025.000000    50.000000   \n",
            "\n",
            "             pdays     previous  \n",
            "count  4521.000000  4521.000000  \n",
            "mean     39.766645     0.542579  \n",
            "std     100.121124     1.693562  \n",
            "min      -1.000000     0.000000  \n",
            "25%      -1.000000     0.000000  \n",
            "50%      -1.000000     0.000000  \n",
            "75%      -1.000000     0.000000  \n",
            "max     871.000000    25.000000  \n",
            "\n",
            "カテゴリ列の記述統計情報:\n",
            "               job  marital  education default housing  loan   contact month  \\\n",
            "count         4521     4521       4521    4521    4521  4521      4521  4521   \n",
            "unique          12        3          4       2       2     2         3    12   \n",
            "top     management  married  secondary      no     yes    no  cellular   may   \n",
            "freq           969     2797       2306    4445    2559  3830      2896  1398   \n",
            "\n",
            "       poutcome     y  \n",
            "count      4521  4521  \n",
            "unique        4     2  \n",
            "top     unknown    no  \n",
            "freq       3705  4000  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('bank.csv', sep=';')\n",
        "\n",
        "# 1. 全ての列名を表示\n",
        "print(\"列名:\")\n",
        "print(df.columns)\n",
        "\n",
        "# 2. 各列のデータ型を表示\n",
        "print(\"\\n各列のデータ型:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# 3. 特定の列のユニークな値を表示（例として「job」列）\n",
        "print(\"\\n「job」列のユニークな値:\")\n",
        "print(df['job'].unique())\n",
        "\n",
        "# 4. データセットの基本情報を表示\n",
        "print(\"\\nデータセットの基本情報:\")\n",
        "print(df.info())\n",
        "\n",
        "# 5. 最初の数行のデータを表示\n",
        "print(\"\\n最初の5行のデータ:\")\n",
        "print(df.head())\n",
        "\n",
        "# 6. 数値列の記述統計情報を表示\n",
        "print(\"\\n数値列の記述統計情報:\")\n",
        "print(df.describe())\n",
        "\n",
        "# カテゴリ列の記述統計情報を表示\n",
        "print(\"\\nカテゴリ列の記述統計情報:\")\n",
        "print(df.describe(include='object'))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, make_scorer\n",
        "from scipy.stats import ttest_rel\n",
        "# 加载数据\n",
        "df = pd.read_csv('bank.csv', sep=';')\n",
        "\n",
        "# 定义处理方法\n",
        "def affine_transform(series):\n",
        "    q_low = series.quantile(0.05)\n",
        "    q_high = series.quantile(0.95)\n",
        "    return 2 * (series - q_low) / (q_high - q_low) - 1\n",
        "\n",
        "def linear_transform(series):\n",
        "    q_high = series.quantile(0.95)\n",
        "    return series / q_high\n",
        "\n",
        "# 1. age: u, cn\n",
        "df['age'] = affine_transform(df['age'])\n",
        "\n",
        "# 2. job: c\n",
        "df = pd.get_dummies(df, columns=['job'], drop_first=True)\n",
        "\n",
        "# 3. marital: c\n",
        "df = pd.get_dummies(df, columns=['marital'], drop_first=True)\n",
        "\n",
        "# 4. education: o\n",
        "education_mapping = {'primary': 1, 'secondary': 2, 'tertiary': 3, 'unknown': 0}\n",
        "df['education'] = df['education'].map(education_mapping)\n",
        "\n",
        "# 5. default: o\n",
        "default_mapping = {'no': 0, 'yes': 1}\n",
        "df['default'] = df['default'].map(default_mapping)\n",
        "\n",
        "# 6. balance: u, cn\n",
        "df['balance'] = affine_transform(df['balance'])\n",
        "\n",
        "# 7. housing: o\n",
        "housing_mapping = {'no': 0, 'yes': 1}\n",
        "df['housing'] = df['housing'].map(housing_mapping)\n",
        "\n",
        "# 8. loan: o\n",
        "loan_mapping = {'no': 0, 'yes': 1}\n",
        "df['loan'] = df['loan'].map(loan_mapping)\n",
        "\n",
        "# 9. contact: u, c\n",
        "df = pd.get_dummies(df, columns=['contact'], drop_first=True)\n",
        "df = pd.get_dummies(df, columns=['month'], drop_first=True)\n",
        "\n",
        "# 10. day: u, cn\n",
        "df['day'] = affine_transform(df['day'])\n",
        "\n",
        "# 11. duration: cn\n",
        "df['duration'] = affine_transform(df['duration'])\n",
        "\n",
        "# 12. campaign: u, n\n",
        "df['campaign'] = linear_transform(df['campaign'])\n",
        "\n",
        "# 13. pdays: del\n",
        "df = df.drop(columns=['pdays'])\n",
        "\n",
        "# 14. previous: u, n\n",
        "df['previous'] = linear_transform(df['previous'])\n",
        "\n",
        "# 15. poutcome: u, c\n",
        "df = pd.get_dummies(df, columns=['poutcome'], drop_first=True)\n",
        "df['y'] = df['y'].map({'yes': 1, 'no': -1})\n",
        "\n",
        "# 计算 PRBEP\n",
        "\n",
        "\n",
        "X = df.drop(columns=['y'])\n",
        "y = df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    stratify=y,\n",
        "    random_state=0\n",
        ")\n",
        "def precision_recall_break_even_point(y_true, y_pred_proba):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred_proba)\n",
        "    diff = np.abs(precision - recall)\n",
        "    idx = np.argmin(diff)\n",
        "    return (precision[idx] + recall[idx]) / 2\n",
        "\n",
        "def prbep_scorer(estimator, X, y):\n",
        "    y_pred_proba = estimator.predict_proba(X)[:, 1]\n",
        "    return precision_recall_break_even_point(y, y_pred_proba)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # liblinear supports both L1 and L2\n",
        "}\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg = LogisticRegression(random_state=0)\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(\n",
        "    logreg,\n",
        "    param_grid,\n",
        "    scoring=prbep_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "print(f\"Best PRBEP score: {best_score}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cnAG4t58a8Em",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3118580e-7973-43e7-9efc-0bcbb4d91006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
            "Best parameters: {'C': 0.615848211066026, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best PRBEP score: 0.5589041095890411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, make_scorer\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# 加载数据\n",
        "df = pd.read_csv('bank.csv', sep=';')\n",
        "\n",
        "# 定义处理方法\n",
        "def affine_transform(series):\n",
        "    q_low = series.quantile(0.05)\n",
        "    q_high = series.quantile(0.95)\n",
        "    return 2 * (series - q_low) / (q_high - q_low) - 1\n",
        "\n",
        "def linear_transform(series):\n",
        "    q_high = series.quantile(0.95)\n",
        "    return series / q_high\n",
        "\n",
        "# 预处理数据\n",
        "df['age'] = affine_transform(df['age'])\n",
        "df['balance'] = affine_transform(df['balance'])\n",
        "df['day'] = affine_transform(df['day'])\n",
        "df['duration'] = affine_transform(df['duration'])\n",
        "df['campaign'] = linear_transform(df['campaign'])\n",
        "df['previous'] = linear_transform(df['previous'])\n",
        "\n",
        "df = pd.get_dummies(df, columns=['job', 'marital', 'contact', 'poutcome', 'month'], drop_first=True)\n",
        "\n",
        "df['y'] = df['y'].map({'yes': 1, 'no': -1})\n",
        "\n",
        "# 计算 PRBEP\n",
        "def calculate_prbep(y_true, y_pred):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
        "    difference = np.abs(precision - recall)\n",
        "    break_even_point = np.argmin(difference)\n",
        "    prbep = (precision[break_even_point] + recall[break_even_point]) / 2\n",
        "    return prbep\n",
        "\n",
        "# 自定义 PRBEP 评分函数\n",
        "def prbep_scorer(y_true, y_pred):\n",
        "    return calculate_prbep(y_true, y_pred)\n",
        "\n",
        "# 交叉验证和 PRBEP 计算\n",
        "def evaluate_model(X_train, y_train, X_test, y_test, norm_type):\n",
        "\n",
        "    model = LogisticRegression(penalty=norm_type, solver='saga',max_iter=1000)\n",
        "    param_grid = {'C': np.logspace(0, 10, 10)}\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(prbep_scorer), error_score='raise')\n",
        "\n",
        "    try:\n",
        "        grid_search.fit(X_train, y_train)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during GridSearchCV: {e}\")\n",
        "        return None\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_probs = best_model.predict_proba(X_test)[:, 1]  # 获取正类的概率\n",
        "    prbep = calculate_prbep(y_test, y_probs)\n",
        "    return prbep\n",
        "\n",
        "# 初始化 PRBEP 存储\n",
        "prbep_l1_scores = []\n",
        "prbep_l2_scores = []\n",
        "\n",
        "# 进行 10 次重复实验\n",
        "for i in range(10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
        "\n",
        "    # 计算 L1 正则化的 PRBEP\n",
        "    prbep_l1 = evaluate_model(X_train, y_train, X_test, y_test, 'l1')\n",
        "    if prbep_l1 is not None:\n",
        "        prbep_l1_scores.append(prbep_l1)\n",
        "\n",
        "    # 计算 L2 正则化的 PRBEP\n",
        "    prbep_l2 = evaluate_model(X_train, y_train, X_test, y_test, 'l2')\n",
        "    if prbep_l2 is not None:\n",
        "        prbep_l2_scores.append(prbep_l2)\n",
        "\n",
        "# 执行独立样本 t 检验\n",
        "t_stat, p_value = ttest_ind(prbep_l1_scores, prbep_l2_scores, equal_var=False)\n",
        "\n",
        "print(f'PRBEP L1 scores: {prbep_l1_scores}')\n",
        "print(f'PRBEP L2 scores: {prbep_l2_scores}')\n",
        "print(f'Independent T-statistic: {t_stat:.4f}')\n",
        "print(f'Independent P-value: {p_value:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "_650Uy7rWw3u",
        "outputId": "f76181ec-4715-4bd4-93cf-cae4f8be8079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-da64b7cc0c10>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# 计算 L2 正则化的 PRBEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mprbep_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprbep_l2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mprbep_l2_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprbep_l2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-da64b7cc0c10>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(X_train, y_train, X_test, y_test, norm_type)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during GridSearchCV: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    843\u001b[0m                     )\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    846\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1304\u001b[0m             path_func(\n\u001b[1;32m   1305\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    531\u001b[0m                 \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             w0, n_iter_i, warm_start_sag = sag_solver(\n\u001b[0m\u001b[1;32m    534\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0msag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msag64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msag32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     num_seen, n_iter_ = sag(\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, make_scorer\n",
        "\n",
        "# 加载数据\n",
        "df = pd.read_csv('bank.csv', sep=';')\n",
        "\n",
        "# 定义处理方法\n",
        "def affine_transform(series):\n",
        "    q_low = series.quantile(0.05)\n",
        "    q_high = series.quantile(0.95)\n",
        "    return 2 * (series - q_low) / (q_high - q_low) - 1\n",
        "\n",
        "def linear_transform(series):\n",
        "    q_high = series.quantile(0.95)\n",
        "    return series / q_high\n",
        "\n",
        "# 预处理数据\n",
        "# 1. age: u, cn\n",
        "df['age'] = affine_transform(df['age'])\n",
        "\n",
        "# 2. job: c\n",
        "df = pd.get_dummies(df, columns=['job'], drop_first=True)\n",
        "\n",
        "# 3. marital: c\n",
        "df = pd.get_dummies(df, columns=['marital'], drop_first=True)\n",
        "\n",
        "# 4. education: o\n",
        "education_mapping = {'primary': 1, 'secondary': 2, 'tertiary': 3, 'unknown': 0}\n",
        "df['education'] = df['education'].map(education_mapping)\n",
        "\n",
        "# 5. default: o\n",
        "default_mapping = {'no': 0, 'yes': 1}\n",
        "df['default'] = df['default'].map(default_mapping)\n",
        "\n",
        "# 6. balance: u, cn\n",
        "df['balance'] = affine_transform(df['balance'])\n",
        "\n",
        "# 7. housing: o\n",
        "housing_mapping = {'no': 0, 'yes': 1}\n",
        "df['housing'] = df['housing'].map(housing_mapping)\n",
        "\n",
        "# 8. loan: o\n",
        "loan_mapping = {'no': 0, 'yes': 1}\n",
        "df['loan'] = df['loan'].map(loan_mapping)\n",
        "\n",
        "# 9. contact: u, c\n",
        "df = pd.get_dummies(df, columns=['contact'], drop_first=True)\n",
        "df = pd.get_dummies(df, columns=['month'], drop_first=True)\n",
        "\n",
        "# 10. day: u, cn\n",
        "df['day'] = affine_transform(df['day'])\n",
        "\n",
        "# 11. duration: cn\n",
        "df['duration'] = affine_transform(df['duration'])\n",
        "\n",
        "# 12. campaign: u, n\n",
        "df['campaign'] = linear_transform(df['campaign'])\n",
        "\n",
        "# 13. pdays: del\n",
        "df = df.drop(columns=['pdays'])\n",
        "\n",
        "# 14. previous: u, n\n",
        "df['previous'] = linear_transform(df['previous'])\n",
        "\n",
        "# 15. poutcome: u, c\n",
        "df = pd.get_dummies(df, columns=['poutcome'], drop_first=True)\n",
        "df['y'] = df['y'].map({'yes': 1, 'no': -1})\n",
        "\n",
        "# 计算 PRBEP\n",
        "def calculate_prbep(y_true, y_pred):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
        "    difference = np.abs(precision - recall)\n",
        "    break_even_point = np.argmin(difference)\n",
        "    prbep = (precision[break_even_point] + recall[break_even_point]) / 2\n",
        "    return prbep\n",
        "\n",
        "# 自定义 PRBEP 评分函数\n",
        "def prbep_scorer(y_true, y_pred):\n",
        "    return calculate_prbep(y_true, y_pred)\n",
        "\n",
        "# 交叉验证和 PRBEP 计算\n",
        "def evaluate_model(X_train, y_train, X_test, y_test, norm_type):\n",
        "    model = LogisticRegression(penalty=norm_type, solver='saga', max_iter=1000)\n",
        "    param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(prbep_scorer), error_score='raise')\n",
        "\n",
        "    try:\n",
        "        grid_search.fit(X_train, y_train)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during GridSearchCV: {e}\")\n",
        "        return None\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_probs = best_model.predict_proba(X_test)[:, 1]  # 获取正类的概率\n",
        "    prbep = calculate_prbep(y_test, y_probs)\n",
        "    return prbep\n",
        "\n",
        "\n",
        "\n",
        "# 初始化 PRBEP 存储\n",
        "prbep_l1_scores = []\n",
        "prbep_l2_scores = []\n",
        "\n",
        "# 数据分割\n",
        "X = df.drop(columns=['y'])\n",
        "y = df['y']\n",
        "\n",
        "# 分别进行 L1 和 L2 正则化的交叉验证\n",
        "for i in range(10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=i)\n",
        "\n",
        "    # 计算 L1 正则化的 PRBEP\n",
        "    prbep_l1 = evaluate_model(X_train, y_train, X_test, y_test, 'l1')\n",
        "    if prbep_l1 is not None:\n",
        "        prbep_l1_scores.append(prbep_l1)\n",
        "\n",
        "    # 计算 L2 正则化的 PRBEP\n",
        "    prbep_l2 = evaluate_model(X_train, y_train, X_test, y_test, 'l2')\n",
        "    if prbep_l2 is not None:\n",
        "        prbep_l2_scores.append(prbep_l2)\n",
        "# 交叉验证和 PRBEP 计算\n",
        "\n",
        "# 输出结果\n",
        "print(f'PRBEP L1 scores: {prbep_l1_scores}')\n",
        "print(f'PRBEP L2 scores: {prbep_l2_scores}')\n",
        "\n",
        "# 进行独立样本 t 检验\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "t_stat, p_value = ttest_ind(prbep_l1_scores, prbep_l2_scores, equal_var=False)\n",
        "\n",
        "print(f'Independent P-value: {p_value:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdA99Y4rfrej",
        "outputId": "6fff318c-e6dd-4355-e17e-186d73827c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRBEP L1 scores: [0.5064102564102564, 0.5192307692307693, 0.5, 0.5448717948717948, 0.5512820512820513, 0.5512820512820513, 0.532051282051282, 0.5576923076923077, 0.532051282051282, 0.532051282051282]\n",
            "PRBEP L2 scores: [0.5128205128205128, 0.5192307692307693, 0.4935897435897436, 0.5448717948717948, 0.5512820512820513, 0.5512820512820513, 0.532051282051282, 0.5448717948717948, 0.5192307692307693, 0.5192307692307693]\n",
            "Independent T-statistic: 0.4453\n",
            "Independent P-value: 0.6614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU97FNSPwfH_",
        "outputId": "74775771-ef33-4835-d667-29dfa8638546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.1.4)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.7.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, make_scorer\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "bank_marketing = fetch_ucirepo(id=222)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = bank_marketing.data.features\n",
        "y = bank_marketing.data.targets\n",
        "\n",
        "df = X.copy()\n",
        "\n",
        "# 定义处理方法\n",
        "def affine_transform(series):\n",
        "    q_low = series.quantile(0.05)\n",
        "    q_high = series.quantile(0.95)\n",
        "    return 2 * (series - q_low) / (q_high - q_low) - 1\n",
        "\n",
        "def linear_transform(series):\n",
        "    q_high = series.quantile(0.95)\n",
        "    return series / q_high\n",
        "\n",
        "# 预处理数据\n",
        "df['age'] = affine_transform(df['age'])\n",
        "\n",
        "# 2. 对分类变量 'job' 进行 one-hot 编码\n",
        "df = pd.get_dummies(df, columns=['job'], drop_first=True)\n",
        "\n",
        "# 3. 对分类变量 'marital' 进行 one-hot 编码\n",
        "df = pd.get_dummies(df, columns=['marital'], drop_first=True)\n",
        "\n",
        "# 4. education: o\n",
        "education_mapping = {'primary': 1, 'secondary': 2, 'tertiary': 3, 'unknown': 0}\n",
        "df['education'] = df['education'].map(education_mapping)\n",
        "\n",
        "# 5. default: o\n",
        "default_mapping = {'no': 0, 'yes': 1}\n",
        "df['default'] = df['default'].map(default_mapping)\n",
        "\n",
        "# 6. balance: u, cn\n",
        "df['balance'] = affine_transform(df['balance'])\n",
        "\n",
        "# 7. housing: o\n",
        "housing_mapping = {'no': 0, 'yes': 1}\n",
        "df['housing'] = df['housing'].map(housing_mapping)\n",
        "\n",
        "# 8. loan: o\n",
        "loan_mapping = {'no': 0, 'yes': 1}\n",
        "df['loan'] = df['loan'].map(loan_mapping)\n",
        "\n",
        "# 9. contact: u, c\n",
        "df = pd.get_dummies(df, columns=['contact'], drop_first=True)\n",
        "df = pd.get_dummies(df, columns=['month'], drop_first=True)\n",
        "\n",
        "# 10. day: u, cn\n",
        "df['day_of_week'] = affine_transform(df['day_of_week'])\n",
        "\n",
        "# 11. duration: cn\n",
        "df['duration'] = affine_transform(df['duration'])\n",
        "\n",
        "# 12. campaign: u, n\n",
        "df['campaign'] = linear_transform(df['campaign'])\n",
        "\n",
        "# 13. pdays: del\n",
        "df = df.drop(columns=['pdays'])\n",
        "\n",
        "# 14. previous: u, n\n",
        "df['previous'] = linear_transform(df['previous'])\n",
        "\n",
        "# 15. poutcome: u, c\n",
        "df = pd.get_dummies(df, columns=['poutcome'], drop_first=True)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    stratify=y,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# 计算 PRBEP\n",
        "def calculate_prbep(y_true, y_pred):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
        "    difference = np.abs(precision - recall)\n",
        "    break_even_point = np.argmin(difference)\n",
        "    prbep = (precision[break_even_point] + recall[break_even_point]) / 2\n",
        "    return prbep\n",
        "\n",
        "# 自定义 PRBEP 评分函数\n",
        "def prbep_scorer(y_true, y_pred):\n",
        "    return calculate_prbep(y_true, y_pred)\n",
        "\n",
        "# 交叉验证和 PRBEP 计算\n",
        "from sklearn.metrics import make_scorer, precision_recall_curve, average_precision_score\n",
        "\n",
        "def evaluate_model(X_train, y_train, X_test, y_test, norm_type):\n",
        "    # 选择模型\n",
        "    if norm_type == 'l2':\n",
        "        model = SomeModel(normalize='l2')  # 根据需要替换为实际模型\n",
        "    elif norm_type == 'l1':\n",
        "        model = SomeModel(normalize='l1')  # 根据需要替换为实际模型\n",
        "    else:\n",
        "        raise ValueError(\"Invalid normalization type\")\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # 计算 PRBEP\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "    prbep = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "    return prbep\n",
        "\n",
        "prbep_l2 = evaluate_model(X_train, y_train, X_test, y_test, 'l2')\n",
        "print(f'PRBEP with L2 normalization: {prbep_l2:.4f}')\n",
        "prbep_l1 = evaluate_model(X_train, y_train, X_test, y_test, 'l1')\n",
        "print(f'PRBEP with L1 normalization: {prbep_l1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "gL7nWhX8tC2k",
        "outputId": "8288a13f-578c-48fd-e51d-8fc8d08fd2d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      age  education  default   balance  housing  loan  day_of_week  duration  \\\n",
            "0  0.9375        3.0        0 -0.220539        1     0    -0.846154 -0.368715   \n",
            "1  0.0625        2.0        0 -0.932323        1     0    -0.846154 -0.675978   \n",
            "2 -0.6250        2.0        0 -0.941414        1     1    -0.846154 -0.885475   \n",
            "3  0.2500        NaN        0 -0.435017        1     0    -0.846154 -0.840782   \n",
            "4 -0.6250        NaN        0 -0.941751        0     0    -0.846154 -0.544693   \n",
            "\n",
            "   campaign  previous  ...  month_jan  month_jul  month_jun  month_mar  \\\n",
            "0     0.125       0.0  ...      False      False      False      False   \n",
            "1     0.125       0.0  ...      False      False      False      False   \n",
            "2     0.125       0.0  ...      False      False      False      False   \n",
            "3     0.125       0.0  ...      False      False      False      False   \n",
            "4     0.125       0.0  ...      False      False      False      False   \n",
            "\n",
            "   month_may  month_nov  month_oct  month_sep  poutcome_other  \\\n",
            "0       True      False      False      False           False   \n",
            "1       True      False      False      False           False   \n",
            "2       True      False      False      False           False   \n",
            "3       True      False      False      False           False   \n",
            "4       True      False      False      False           False   \n",
            "\n",
            "   poutcome_success  \n",
            "0             False  \n",
            "1             False  \n",
            "2             False  \n",
            "3             False  \n",
            "4             False  \n",
            "\n",
            "[5 rows x 36 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SomeModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6b6d00f8b6ff>\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprbep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mprbep_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'PRBEP with L2 normalization: {prbep_l2:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mprbep_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-6b6d00f8b6ff>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(X_train, y_train, X_test, y_test, norm_type)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# 选择模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnorm_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSomeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 根据需要替换为实际模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnorm_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSomeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 根据需要替换为实际模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SomeModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMKeuNCqDURG",
        "outputId": "2f9ad0ad-b1fb-4a50-d97e-c3bed4d779b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.1.4)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.7.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, make_scorer\n",
        "# fetch dataset\n",
        "statlog_australian_credit_approval = fetch_ucirepo(id=143)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = statlog_australian_credit_approval.data.features\n",
        "y = statlog_australian_credit_approval.data.targets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    stratify=y,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# 计算 PRBEP\n",
        "def calculate_prbep(y_true, y_pred):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
        "    difference = np.abs(precision - recall)\n",
        "    break_even_point = np.argmin(difference)\n",
        "    prbep = (precision[break_even_point] + recall[break_even_point]) / 2\n",
        "    return prbep\n",
        "\n",
        "# 自定义 PRBEP 评分函数\n",
        "def prbep_scorer(y_true, y_pred):\n",
        "    return calculate_prbep(y_true, y_pred)\n",
        "\n",
        "# 交叉验证和 PRBEP 计算\n",
        "def evaluate_model(X_train, y_train, X_test, y_test, norm_type):\n",
        "    model = LogisticRegression(penalty=norm_type, solver='saga', max_iter=10000)\n",
        "    param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(prbep_scorer), error_score='raise')\n",
        "\n",
        "    try:\n",
        "        grid_search.fit(X_train, y_train)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during GridSearchCV: {e}\")\n",
        "        return None\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_probs = best_model.predict_proba(X_test)[:, 1]  # 获取正类的概率\n",
        "    print(f\"Best model for {norm_type} regularization: {best_model}\")\n",
        "    prbep = calculate_prbep(y_test, y_probs)\n",
        "    return prbep\n",
        "\n",
        "prbep_l2 = evaluate_model(X_train, y_train, X_test, y_test, 'l2')\n",
        "print(f'PRBEP with L2 normalization: {prbep_l2:.4f}')\n",
        "prbep_l1 = evaluate_model(X_train, y_train, X_test, y_test, 'l1')\n",
        "print(f'PRBEP with L1 normalization: {prbep_l1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV9f5fB6DXam",
        "outputId": "6f6c6327-a26d-4ae0-8dc8-ed71d5119730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for l2 regularization: LogisticRegression(C=0.01, max_iter=10000, solver='saga')\n",
            "PRBEP with L2 normalization: 0.6739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for l1 regularization: LogisticRegression(C=1, max_iter=10000, penalty='l1', solver='saga')\n",
            "PRBEP with L1 normalization: 0.6739\n"
          ]
        }
      ]
    }
  ]
}