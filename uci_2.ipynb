{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrjY1qbZsF9s",
        "outputId": "281a53af-d496-408b-aad0-587fc7b30425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.1.4)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.7.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "def fetch_data(id):\n",
        "    data = fetch_ucirepo(id=id)\n",
        "    X = data.data.features\n",
        "    y = data.data.targets\n",
        "    return X, y\n",
        "\n",
        "def preprocess_y(y):\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y.values.ravel())\n",
        "    if le.classes_.size == 2:\n",
        "        return y_encoded, le.classes_\n",
        "    else:\n",
        "        return preprocess_y_binary_most_common(y_encoded)\n",
        "\n",
        "\n",
        "def preprocess_y_binary_most_common(y):\n",
        "    \"\"\"\n",
        "    Convert the most common class in y to 1 and all other classes to -1.\n",
        "\n",
        "    Args:\n",
        "    y (array-like): Input labels.\n",
        "\n",
        "    Returns:\n",
        "    tuple: (preprocessed_y, most_common_class, class_mapping)\n",
        "        preprocessed_y: numpy array with 1 for most common class, -1 for others\n",
        "        most_common_class: the original label of the most common class\n",
        "        class_mapping: dictionary mapping original classes to new values\n",
        "    \"\"\"\n",
        "    # Find the most common class\n",
        "    class_counts = Counter(y)\n",
        "    most_common_class = class_counts.most_common(1)[0][0]\n",
        "\n",
        "    # Create a mapping dictionary\n",
        "    class_mapping = {class_label: -1 for class_label in class_counts.keys()}\n",
        "    class_mapping[most_common_class] = 1\n",
        "\n",
        "    # Convert y to numpy array if it's not already\n",
        "    y_array = np.array(y)\n",
        "\n",
        "    # Apply the mapping\n",
        "    preprocessed_y = np.array([class_mapping[label] for label in y_array])\n",
        "    return preprocessed_y, class_counts.keys()\n",
        "\n",
        "def preprocess(X):\n",
        "    # Identify numeric and categorical columns\n",
        "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Create preprocessing pipelines\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessing steps\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "\n",
        "    X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "    numeric_feature_names = numeric_features.tolist()\n",
        "    if categorical_features.size > 0:\n",
        "        categorical_feature_names = preprocessor.named_transformers_['cat']\\\n",
        "            .named_steps['onehot'].get_feature_names_out(categorical_features).tolist()\n",
        "    else:\n",
        "        categorical_feature_names = []\n",
        "\n",
        "\n",
        "    feature_names = numeric_feature_names + categorical_feature_names\n",
        "    if isinstance(X_preprocessed, csr_matrix):\n",
        "        return pd.DataFrame(X_preprocessed.toarray(), columns=feature_names)\n",
        "    return pd.DataFrame(X_preprocessed, columns=feature_names)\n",
        "\n",
        "# X, y = fetch_data(222) # bank\n",
        "  X, y = fetch_data(143) # australian\n",
        "# X, y = fetch_data(19) # car\n",
        "# X, y = fetch_data(30) # contraceptive\n",
        "# X, y = fetch_data(38) # echocardiogram\n",
        "# X, y = fetch_data(144) # German\n",
        "# X, y = fetch_data(46) # Hepatitis\n",
        "# X, y = fetch_data(225) # ILPD\n",
        "# X, y = fetch_data(236) # Seeds, not available for import\n",
        "# X, y = fetch_data(95) # SPECT Heart\n",
        "# X, y = fetch_data(100) # TAE,  not available for import\n",
        "# X, y = fetch_data(107) # Waveform v1\n",
        "# X, y = fetch_data(108) # Waveform v2,ã€€not available for import\n",
        "# X, y = fetch_data(292) # Wholesale\n",
        "# Preprocess the data\n",
        "X_preprocessed_df = preprocess(X)\n",
        "y, y_classes = preprocess_y(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed_df, y, test_size=0.3, random_state=0)\n",
        "\n",
        "print(\"Preprocessed data shape:\", X_preprocessed_df.shape)\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "TbggbwpmsKxi",
        "outputId": "fca70167-4c63-45bf-fbf1-6227272fb323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 98)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m98\u001b[0m\n\u001b[0;31m    X, y = fetch_data(143) # australian\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Function to calculate Precision-Recall Break-Even Point (PRBEP)\n",
        "def precision_recall_break_even_point(y_true, y_pred_proba):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred_proba)\n",
        "    diff = np.abs(precision - recall)\n",
        "    idx = np.argmin(diff)\n",
        "    return (precision[idx] + recall[idx]) / 2\n",
        "\n",
        "# Custom scorer function for GridSearchCV\n",
        "def prbep_scorer(estimator, X, y):\n",
        "    y_pred_proba = estimator.predict_proba(X)[:, 1]\n",
        "    return precision_recall_break_even_point(y, y_pred_proba)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # liblinear supports both L1 and L2\n",
        "}\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg = LogisticRegression(random_state=0)\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(\n",
        "    logreg,\n",
        "    param_grid,\n",
        "    scoring=prbep_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "print(f\"Best PRBEP score: {best_score}\")\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "test_prbep = precision_recall_break_even_point(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"PRBEP on test set: {test_prbep}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H4wNGQ2sgVh",
        "outputId": "de5ebc69-2264-4113-c980-f79c97fde649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
            "Best parameters: {'C': 0.23357214690901212, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best PRBEP score: 0.5662423769027947\n",
            "PRBEP on test set: 0.55375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Repeat the evaluation 10 times\n",
        "n_iterations = 10\n",
        "prbep_scores = []\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    # Generate a new test set for each iteration\n",
        "    _, X_test, _, y_test = train_test_split(X_preprocessed_df, y, test_size=0.3, random_state=i)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "    test_prbep = precision_recall_break_even_point(y_test, y_pred_proba)\n",
        "    prbep_scores.append(test_prbep)\n",
        "\n",
        "    print(f\"Iteration {i+1}: PRBEP on test set: {test_prbep}\")\n",
        "\n",
        "# Perform one-sample t-test\n",
        "t_statistic, p_value = stats.ttest_1samp(prbep_scores, 0.5)  # Test against PRBEP of 0.5\n",
        "\n",
        "# Create a P-value table\n",
        "p_value_table = pd.DataFrame({\n",
        "    'Metric': ['PRBEP'],\n",
        "    'Mean': [np.mean(prbep_scores)],\n",
        "    'Std Dev': [np.std(prbep_scores)],\n",
        "    't-statistic': [t_statistic],\n",
        "    'p-value': [p_value]\n",
        "})\n",
        "\n",
        "print(\"\\nP-value table:\")\n",
        "print(p_value_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhUGMyn9sg9q",
        "outputId": "48cf071b-0d7a-45b9-b207-cd6e38faa12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: PRBEP on test set: 0.5442006269592476\n",
            "Iteration 2: PRBEP on test set: 0.5622179239200515\n",
            "Iteration 3: PRBEP on test set: 0.5565495207667731\n",
            "Iteration 4: PRBEP on test set: 0.5755485893416928\n",
            "Iteration 5: PRBEP on test set: 0.5484508899143046\n",
            "Iteration 6: PRBEP on test set: 0.5709818636647905\n",
            "Iteration 7: PRBEP on test set: 0.5655384615384615\n",
            "Iteration 8: PRBEP on test set: 0.5697522816166884\n",
            "Iteration 9: PRBEP on test set: 0.5688585607940446\n",
            "Iteration 10: PRBEP on test set: 0.55375\n",
            "\n",
            "P-value table:\n",
            "  Metric      Mean   Std Dev  t-statistic       p-value\n",
            "0  PRBEP  0.561585  0.009901     18.65935  1.672831e-08\n"
          ]
        }
      ]
    }
  ]
}